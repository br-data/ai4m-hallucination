# AI 4 Media Hackathon: Hallucination Detection

This repo contains evaluation code, test and training data to detect hallucinated content in generated answers by our RAG 
system ask-br24.

## Test- and Training Data

The test and training data ist purely synthetic. It is generated by a random dump from our vector store containing 
BR24 articles, split by `<p>`aragraphs. For the test set 150 of those paragraphs are randomly sampled and saved to
`data/test.csv`. 

This file is used by `create_training_data.py` to generate a question which can be answered given the paragraph.

Using this question and the paragraph, GPT 3.5 Turbo is used to generate answers to the questions. In some cases
the LLM is explicitly asked to add wrong but plausible content to the answer.

## Hypothesis data

Your hypothesis data should be placed in the data folder and be suffixed with `_result.jsonl`. Each row shall contain a 
JSON object with the structure as follows:

```json
{
  "id": "string",
  "hallucination": true,
  "prob": 0.01
}
```

## Evaluation
To run the evaluation simply run `python evaluate.py` after you've placed your results in the data folder.

The evaluation script calculates the accuracy - e.g. the percentage of correctly predicted samples.